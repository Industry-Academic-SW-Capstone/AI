import pandas as pd
import numpy as np
import joblib
import persona_definitions as pd_data  # í˜ë¥´ì†Œë‚˜ ì •ì˜
from numpy.linalg import norm  # ì¼ì¹˜ìœ¨ ê³„ì‚°

# ----------------------------------------------------
# 1. AI í•µì‹¬ ëª¨ë“ˆ ë¡œë“œ (ë‡Œ + ë²ˆì—­ê¸°)
# ----------------------------------------------------
try:
    model = joblib.load('kmeans_model.pkl')
    scaler = joblib.load('scaler.pkl')
    print("âœ… AI ëª¨ë¸(kmeans_model.pkl) ë° ë²ˆì—­ê¸°(scaler.pkl) ë¡œë“œ ì„±ê³µ.")
except FileNotFoundError:
    print("ğŸš¨ ì˜¤ë¥˜: ëª¨ë¸ íŒŒì¼(.pkl)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 01, 02 ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
    exit()

# ----------------------------------------------------
# 2. ê°€ìƒì˜ ì¬ë¬´ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ (API ì‹œë®¬ë ˆì´ì…˜)
# ----------------------------------------------------
try:
    # ì‹¤ì œë¡œëŠ” ì´ ë¶€ë¶„ì„ API í˜¸ì¶œë¡œ ëŒ€ì²´í•´ì•¼ í•©ë‹ˆë‹¤.
    stock_db = pd.read_csv('dummy_stock_db.csv', encoding='utf-8', dtype={'ë‹¨ì¶•ì½”ë“œ': str})
    stock_db['ë‹¨ì¶•ì½”ë“œ'] = stock_db['ë‹¨ì¶•ì½”ë“œ'].str.strip()
    print("âœ… ê°€ìƒ ì¬ë¬´ DB(dummy_stock_db.csv) ë¡œë“œ ì„±ê³µ.")
except FileNotFoundError:
    print("ğŸš¨ ì˜¤ë¥˜: 'dummy_stock_db.csv' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")
    exit()

# ----------------------------------------------------
# 3. ê°€ìƒì˜ ì‚¬ìš©ì í¬íŠ¸í´ë¦¬ì˜¤ (ë”ë¯¸ ë°ì´í„°)
# ----------------------------------------------------
# ì‹œë®¬ë ˆì´ì…˜: "ì‚¼ì„±ì „ì(50%) + DBí•˜ì´í…(50%)"ë¥¼ êµ¬ë§¤í•œ ì‚¬ìš©ì
user_portfolio_data = {
    'ë‹¨ì¶•ì½”ë“œ': ['001040', '0036930'],
    'íˆ¬ìê¸ˆì•¡': [1000000, 1000000]  # 50% : 50%
}
user_df = pd.DataFrame(user_portfolio_data)
user_df['ë‹¨ì¶•ì½”ë“œ'] = user_df['ë‹¨ì¶•ì½”ë“œ'].astype(str).str.strip()


# ----------------------------------------------------
# 4. (í•µì‹¬) AI ì˜ˆì¸¡ ì—”ì§„ (Phase 2)
# ----------------------------------------------------
def get_style_vector(user_portfolio_df, stock_db, scaler, model):
    # 1. ì‚¬ìš©ìì˜ ì£¼ì‹ ì½”ë“œì— í•´ë‹¹í•˜ëŠ” ì¬ë¬´ ë°ì´í„°ë¥¼ DBì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤. (API í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜)
    merged_df = pd.merge(user_portfolio_df, stock_db, on='ë‹¨ì¶•ì½”ë“œ', how='left')

    # 2. AIê°€ ë¶„ì„í•  6ê°€ì§€ ì¬ë£Œ(Feature)ë¥¼ ë¶„ë¦¬í•©ë‹ˆë‹¤.
    feature_columns = ['ì‹œê°€ì´ì•¡', 'per', 'pbr', 'ROE', 'ë¶€ì±„ë¹„ìœ¨', 'ë°°ë‹¹ìˆ˜ìµë¥ ']
    features_data = merged_df[feature_columns]

    # 3. AI 'ë²ˆì—­ê¸°(Scaler)'ë¡œ ì¬ë¬´ ë°ì´í„°ë¥¼ ë²ˆì—­(ìŠ¤ì¼€ì¼ë§)í•©ë‹ˆë‹¤.
    #    .transform() ì‚¬ìš©ì´ ì¤‘ìš”!
    scaled_data = scaler.transform(features_data)

    # 4. AI 'ë‡Œ(Model)'ì—ê²Œ ì˜ˆì¸¡ì„ ëª…ë ¹í•©ë‹ˆë‹¤.
    predicted_groups = model.predict(scaled_data)  # [5, 1] (ì˜ˆì‹œ)

    # 5. ì˜ˆì¸¡ëœ ê·¸ë£¹ ë²ˆí˜¸ë¥¼ í¬íŠ¸í´ë¦¬ì˜¤ì— ì¶”ê°€í•©ë‹ˆë‹¤.
    merged_df['group_tag'] = predicted_groups

    # 6. íˆ¬ìê¸ˆì•¡ ê¸°ì¤€ìœ¼ë¡œ ë¹„ì¤‘(Weight)ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    merged_df['ë¹„ì¤‘'] = merged_df['íˆ¬ìê¸ˆì•¡'] / merged_df['íˆ¬ìê¸ˆì•¡'].sum()

    # 7. ê·¸ë£¹ë³„ë¡œ ë¹„ì¤‘ì„ í•©ì‚°í•˜ì—¬ ì‚¬ìš©ìì˜ ìµœì¢… ìŠ¤íƒ€ì¼ ë²¡í„°(U)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    user_style_raw = merged_df.groupby('group_tag')['ë¹„ì¤‘'].sum()
    all_groups = np.arange(8)
    user_style_vector = user_style_raw.reindex(all_groups, fill_value=0.0).values

    # 8. ì •ê·œí™”ëœ ë²¡í„°(ì´í•© 1.0)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    vector_sum = user_style_vector.sum()
    if vector_sum == 0: return None

    return user_style_vector / vector_sum


# ----------------------------------------------------
# 5. í˜ë¥´ì†Œë‚˜ ë§¤ì¹­ (Phase 3) - (05ë²ˆ ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼)
# ----------------------------------------------------
def calculate_persona_match(user_vector):
    results = {}
    for name, persona_style_dict in pd_data.ALL_PERSONAS.items():
        all_groups = np.arange(8)
        persona_vector = pd.Series(persona_style_dict).reindex(all_groups, fill_value=0.0).values

        distance = norm(user_vector - persona_vector)
        max_distance = np.sqrt(2.0)
        similarity = max(0, 100 - ((distance / max_distance) * 100))
        results[name] = round(similarity, 2)

    return results


# ----------------------------------------------------
# 6. ì‹¤í–‰ ë° ê²°ê³¼ ì¶œë ¥
# ----------------------------------------------------
if __name__ == "__main__":

    # AI ì˜ˆì¸¡ ì—”ì§„ ì‹¤í–‰!
    user_vector = get_style_vector(user_df, stock_db, scaler, model)

    if user_vector is not None:
        print("\n" + "=" * 40)
        print("           ğŸš€ ì‚¬ìš©ì í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ ê²°ê³¼ (ì˜ˆì¸¡ ì—”ì§„)")
        print("=" * 40)

        # 2-1. ì‚¬ìš©ì ìŠ¤íƒ€ì¼ íƒœê·¸ ë¹„ì¤‘ ì¶œë ¥
        print("ğŸ“Š ì‚¬ìš©ì ìŠ¤íƒ€ì¼ íƒœê·¸ ë¹„ì¤‘:")
        tag_names = ['[ì•ˆì •í˜• ì¼ë°˜ì£¼]', '[ê³ íš¨ìœ¨ ìš°ëŸ‰ì£¼]', '[ì´ˆê³ ë°°ë‹¹ ê°€ì¹˜ì£¼]', '[ê³ ìœ„í—˜ ì €í‰ê°€ì£¼]',
                     '[ê³ ì„±ì¥ ê¸°ëŒ€ì£¼]', '[ì´ˆëŒ€í˜• ìš°ëŸ‰ì£¼]', '[ì´ˆì €í‰ê°€ ê°€ì¹˜ì£¼]', '[ê³ ê°€ì¹˜ ì„±ì¥ì£¼]']

        user_style_summary = [(tag_names[i], user_vector[i] * 100) for i in range(8) if user_vector[i] > 0]

        for name, percent in sorted(user_style_summary, key=lambda item: item[1], reverse=True):
            print(f"- {name}: {percent:.2f}%")

        print("\n" + "-" * 40)

        # 3. í˜ë¥´ì†Œë‚˜ ë§¤ì¹­ ê²°ê³¼ ì¶œë ¥
        match_results = calculate_persona_match(user_vector)

        print("âœ¨ í˜ë¥´ì†Œë‚˜ ì¼ì¹˜ìœ¨ (ë‹¹ì‹ ì˜ ë¡¤ëª¨ë¸):")
        sorted_results = sorted(match_results.items(), key=lambda item: item[1], reverse=True)

        for name, percent in sorted_results:
            print(f"- {name}: {percent:.2f}%")

        print("\n" + "=" * 40)