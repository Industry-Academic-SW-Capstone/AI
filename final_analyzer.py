import pandas as pd
import numpy as np
import joblib
from app.ai_models import persona_definitions as pd_data
from numpy.linalg import norm  # ì¼ì¹˜ìœ¨ ê³„ì‚°

# ----------------------------------------------------
# 1. AI í•µì‹¬ ëª¨ë“ˆ ë¡œë“œ (ë‡Œ + ë²ˆì—­ê¸°)
# ----------------------------------------------------
try:
    model = joblib.load('kmeans_model.pkl')
    scaler = joblib.load('scaler.pkl')
    print("âœ… AI ëª¨ë¸(kmeans_model.pkl) ë° ë²ˆì—­ê¸°(scaler.pkl) ë¡œë“œ ì„±ê³µ.")
except FileNotFoundError:
    print("ğŸš¨ ì˜¤ë¥˜: ëª¨ë¸ íŒŒì¼(.pkl)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 01, 02 ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
    exit()

# ----------------------------------------------------
# 2. ê°€ìƒì˜ ì¬ë¬´ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ (API ì‹œë®¬ë ˆì´ì…˜)
# ----------------------------------------------------
try:
    stock_db = pd.read_csv('app/data/dummy_stock_db.csv', encoding='utf-8', dtype={'ë‹¨ì¶•ì½”ë“œ': str})
    stock_db['ë‹¨ì¶•ì½”ë“œ'] = stock_db['ë‹¨ì¶•ì½”ë“œ'].str.strip()
    print("âœ… ê°€ìƒ ì¬ë¬´ DB(dummy_stock_db.csv) ë¡œë“œ ì„±ê³µ.")
except FileNotFoundError:
    print("ğŸš¨ ì˜¤ë¥˜: 'dummy_stock_db.csv' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")
    exit()

# ----------------------------------------------------
# 3. ê°€ìƒì˜ ì‚¬ìš©ì í¬íŠ¸í´ë¦¬ì˜¤ (ë”ë¯¸ ë°ì´í„°)
# ----------------------------------------------------
# ì‹œë®¬ë ˆì´ì…˜: "ì‚¼ì„±ì „ì(50%) + DBí•˜ì´í…(50%)"ë¥¼ êµ¬ë§¤í•œ ì‚¬ìš©ì
user_portfolio_data = {
    'ë‹¨ì¶•ì½”ë“œ': ['005930', '000990'],
    'íˆ¬ìê¸ˆì•¡': [1000000, 1000000]  # 50% : 50%
}
user_df = pd.DataFrame(user_portfolio_data)
user_df['ë‹¨ì¶•ì½”ë“œ'] = user_df['ë‹¨ì¶•ì½”ë“œ'].astype(str).str.strip()


# ----------------------------------------------------
# 4. (í•µì‹¬) AI ì˜ˆì¸¡ ì—”ì§„ (Phase 2)
# ----------------------------------------------------
def get_style_vector(user_portfolio_df, stock_db, scaler, model):
    merged_df = pd.merge(user_portfolio_df, stock_db, on='ë‹¨ì¶•ì½”ë“œ', how='left')
    feature_columns = ['ì‹œê°€ì´ì•¡', 'per', 'pbr', 'ROE', 'ë¶€ì±„ë¹„ìœ¨', 'ë°°ë‹¹ìˆ˜ìµë¥ ']
    features_data = merged_df[feature_columns]
    scaled_data = scaler.transform(features_data)
    predicted_groups = model.predict(scaled_data)
    merged_df['group_tag'] = predicted_groups

    tag_mapping = {
        0: '[ì•ˆì •í˜• ì¼ë°˜ì£¼]', 1: '[ê³ íš¨ìœ¨ ìš°ëŸ‰ì£¼]', 2: '[ì´ˆê³ ë°°ë‹¹ ê°€ì¹˜ì£¼]',
        3: '[ê³ ìœ„í—˜ ì €í‰ê°€ì£¼]', 4: '[ê³ ì„±ì¥ ê¸°ëŒ€ì£¼]', 5: '[ì´ˆëŒ€í˜• ìš°ëŸ‰ì£¼]',
        6: '[ì´ˆì €í‰ê°€ ê°€ì¹˜ì£¼]', 7: '[ê³ ê°€ì¹˜ ì„±ì¥ì£¼]'
    }
    description_mapping = {
        0: "ì•ˆì •ì ì¸ ë³´í†µ ì£¼ì‹: íšŒì‚¬ê°€ ë¹š(ë¶€ì±„)ì´ ì ì–´ì„œ ì¼ë‹¨ ë§í•  ìœ„í—˜ì´ ë‚®ì•„ìš”. í•˜ì§€ë§Œ ëˆì„ ë²Œì–´ë“¤ì´ëŠ” íš¨ìœ¨(ROE)ì´ í‰ë²”í•´ì„œ, ì£¼ê°€ê°€ í­ë°œì ìœ¼ë¡œ ì˜¤ë¥´ì§€ë„ ì•Šì„ ê±°ì˜ˆìš”.",
        1: "ìˆ¨ê²¨ì§„ ë³´ë¬¼ ìš°ëŸ‰ì£¼: PERì´ ë‚®ì•„ì„œ (ë²„ëŠ” ëˆ ëŒ€ë¹„ ì£¼ê°€ê°€ ì €ë ´í•´ì„œ) ì €í‰ê°€ë˜ì–´ ìˆì–´ìš”. ê²Œë‹¤ê°€ ROEê°€ ë†’ì•„ì„œ (ìê¸° ëˆìœ¼ë¡œ ì¥ì‚¬ë¥¼ ë§¤ìš° ì˜í•´ì„œ) íš¨ìœ¨ì„±ì´ ë›°ì–´ë‚œ ë¯¿ìŒì§í•œ ê¸°ì—…ì´ì—ìš”.",
        2: "ì´ˆê³ ë°°ë‹¹ ê°€ì¹˜ì£¼: ë‹¤ë¥¸ ì£¼ì‹ë“¤ë³´ë‹¤ ë°°ë‹¹ìˆ˜ìµë¥ ì´ ì••ë„ì ìœ¼ë¡œ ë†’ì•„ìš”. (ì£¼ì‹ì„ ì€í–‰ ì´ìì²˜ëŸ¼ ì‚¬ëŠ” ê°œë…) PERì´ ë‚®ì•„ (ì €ë ´í•´ì„œ) í˜„ì¬ì˜ ê°€ì¹˜ë„ ê´œì°®ì€ ê·¸ë£¹ì´ì—ìš”.",
        3: "ê³ ìœ„í—˜ ì €í‰ê°€ì£¼: PBRì´ ë§¤ìš° ë‚®ì•„ (íšŒì‚¬ê°€ ê°€ì§„ ì¬ì‚°ë³´ë‹¤ ì£¼ê°€ê°€ í›¨ì”¬ ì‹¸ìš”). But! ë¶€ì±„ë¹„ìœ¨ì´ ë„ˆë¬´ ë†’ì•„ (ë¹šì´ ë§ì•„) ì˜ëª»ë˜ë©´ í¬ê²Œ ìœ„í—˜í•´ì§ˆ ìˆ˜ ìˆì–´ìš”.",
        4: "ê³ ì„±ì¥ ê¸°ëŒ€ì£¼: PERì´ ì—„ì²­ë‚˜ê²Œ ë†’ì•„ìš”. (íšŒì‚¬ê°€ ë²„ëŠ” ëˆì— ë¹„í•´ ì£¼ê°€ê°€ ë§¤ìš° ë¹„ì‹¸ìš”). ì´ëŠ” ì‚¬ëŒë“¤ì´ ì´ íšŒì‚¬ê°€ 'ì•ìœ¼ë¡œ ì—„ì²­ë‚œ ëŒ€ë°•ì„ ì¹  ê²ƒ'ì´ë¼ê³  ê¸°ëŒ€í•˜ê¸° ë•Œë¬¸ì´ì—ìš”.",
        5: "ì´ˆëŒ€í˜• ìš°ëŸ‰ì£¼: ì‹œê°€ì´ì•¡ì´ ê°€ì¥ ì»¤ìš”. (íšŒì‚¬ì˜ ë©ì¹˜ê°€ ê°€ì¥ ì»¤ìš”). ì›Œë‚™ í¬ê¸° ë•Œë¬¸ì— í¬ê²Œ ì˜¤ë¥´ê¸°ëŠ” ì–´ë µì§€ë§Œ, ì‹œì¥ì„ ëŒ€í‘œí•˜ëŠ” ì•ˆì •ì ì¸ ê·¸ë£¹ì´ì—ìš”.",
        6: "ì´ˆì €í‰ê°€ ê°€ì¹˜ì£¼: PERê³¼ PBRì´ ê°€ì¥ ë‚®ê³  (ê°€ì¥ ì €ë ´í•¨) ë¶€ì±„ë¹„ìœ¨ë„ ê°€ì¥ ë‚®ì•„ (ê°€ì¥ ì•ˆì „í•¨) 'ì‹¸ê³  ì•ˆì „í•œ ì¢…ëª©'ì„ ì°¾ëŠ” ì •ì„ì ì¸ ê°€ì¹˜íˆ¬ììë“¤ì´ ì„ í˜¸í•˜ëŠ” ê·¸ë£¹ì´ì—ìš”.",
        7: "ê³ ê°€ì¹˜ ì„±ì¥ì£¼: PBRì´ ë†’ì•„ (ì´ë¯¸ ë¹„ì‹¸ì§€ë§Œ) ROEë„ ë†’ì•„ (ì‹¤ì œë¡œ ëˆë„ ì˜ ë²Œê³  íš¨ìœ¨ë„ ì¢‹ìŒ). ì‹œì¥ì—ì„œ 'ë¹„ì‹¼ ê°’ì„ ì§€ë¶ˆí•  ê°€ì¹˜'ê°€ ìˆë‹¤ê³  ì¸ì •ë°›ëŠ” ì„±ì¥ ê¸°ì—… ê·¸ë£¹ì´ì—ìš”."
    }

    merged_df['final_style_tag'] = merged_df['group_tag'].map(tag_mapping)
    merged_df['style_description'] = merged_df['group_tag'].map(description_mapping)

    merged_df['ë¹„ì¤‘'] = merged_df['íˆ¬ìê¸ˆì•¡'] / merged_df['íˆ¬ìê¸ˆì•¡'].sum()
    user_style_raw = merged_df.groupby('group_tag')['ë¹„ì¤‘'].sum()
    all_groups = np.arange(8)
    user_style_vector = user_style_raw.reindex(all_groups, fill_value=0.0).values

    vector_sum = user_style_vector.sum()
    if vector_sum == 0: return None, None

    return user_style_vector / vector_sum, merged_df


# ----------------------------------------------------
# 5. í˜ë¥´ì†Œë‚˜ ë§¤ì¹­ (Phase 3) - (ë³€ê²½ ì—†ìŒ)
# ----------------------------------------------------
def calculate_persona_match(user_vector):
    results = {}
    for name, persona_style_dict in pd_data.ALL_PERSONAS.items():
        all_groups = np.arange(8)
        persona_vector = pd.Series(persona_style_dict).reindex(all_groups, fill_value=0.0).values

        distance = norm(user_vector - persona_vector)
        max_distance = np.sqrt(2.0)
        similarity = max(0, 100 - ((distance / max_distance) * 100))
        results[name] = round(similarity, 2)

    return results


# ----------------------------------------------------
# 6. ì‹¤í–‰ ë° ê²°ê³¼ ì¶œë ¥ (â˜…ì—…ê·¸ë ˆì´ë“œëœ ë¶€ë¶„â˜…)
# ----------------------------------------------------
if __name__ == "__main__":

    user_vector, merged_details = get_style_vector(user_df, stock_db, scaler, model)

    if user_vector is not None:
        print("\n" + "=" * 50)
        print("           ğŸš€ ì‚¬ìš©ì í¬íŠ¸í´ë¦¬ì˜¤ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸")
        print("=" * 50)

        # [1] ë³´ìœ  ì¢…ëª© ìƒì„¸ ë¶„ì„
        print("âœ… [1] ë³´ìœ  ì¢…ëª© ìƒì„¸ ë¶„ì„ (AI ì˜ˆì¸¡)")
        print("-" * 50)
        for index, row in merged_details.iterrows():
            if pd.notna(row['final_style_tag']):
                print(f"ğŸ“Š ì¢…ëª©ëª…: {row['í•œê¸€ëª…']} ({row['ë‹¨ì¶•ì½”ë“œ']})")
                print(f"   - AI ìŠ¤íƒ€ì¼: {row['final_style_tag']}")
                print(f"   - ì£¼ë¦°ì´ í•´ì„¤: {row['style_description']}")

        # [2] í¬íŠ¸í´ë¦¬ì˜¤ ì¢…í•© ì„±í–¥
        print("\n" + "=" * 50)
        print("âœ… [2] í¬íŠ¸í´ë¦¬ì˜¤ ì¢…í•© ì„±í–¥ (ê°€ì¤‘ í‰ê· )")
        print("-" * 50)

        feature_columns = ['ì‹œê°€ì´ì•¡', 'per', 'pbr', 'ROE', 'ë¶€ì±„ë¹„ìœ¨', 'ë°°ë‹¹ìˆ˜ìµë¥ ']
        avg_metrics = {}
        for col in feature_columns:
            weighted_avg = (merged_details[col] * merged_details['ë¹„ì¤‘']).sum()
            avg_metrics[col] = weighted_avg

        print(f"   - í‰ê·  PER (ì„±ì¥ì„±): {avg_metrics['per']:.2f} ë°°")
        print(f"   - í‰ê·  PBR (ìì‚°ê°€ì¹˜): {avg_metrics['pbr']:.2f} ë°°")
        print(f"   - í‰ê·  ROE (íš¨ìœ¨ì„±): {avg_metrics['ROE']:.2f} %")
        print(f"   - í‰ê·  ë¶€ì±„ë¹„ìœ¨ (ì•ˆì •ì„±): {avg_metrics['ë¶€ì±„ë¹„ìœ¨']:.2f} %")
        print(f"   - í‰ê·  ë°°ë‹¹ìˆ˜ìµë¥ : {avg_metrics['ë°°ë‹¹ìˆ˜ìµë¥ ']:.2f} %")

        # [3] ìµœì¢… ìŠ¤íƒ€ì¼ íƒœê·¸ ë¹„ì¤‘
        print("\n" + "=" * 50)
        print("âœ… [3] ìµœì¢… ìŠ¤íƒ€ì¼ íƒœê·¸ ë¹„ì¤‘")
        print("-" * 50)
        tag_names = ['[ì•ˆì •í˜• ì¼ë°˜ì£¼]', '[ê³ íš¨ìœ¨ ìš°ëŸ‰ì£¼]', '[ì´ˆê³ ë°°ë‹¹ ê°€ì¹˜ì£¼]', '[ê³ ìœ„í—˜ ì €í‰ê°€ì£¼]',
                     '[ê³ ì„±ì¥ ê¸°ëŒ€ì£¼]', '[ì´ˆëŒ€í˜• ìš°ëŸ‰ì£¼]', '[ì´ˆì €í‰ê°€ ê°€ì¹˜ì£¼]', '[ê³ ê°€ì¹˜ ì„±ì¥ì£¼]']

        user_style_summary = [(tag_names[i], user_vector[i] * 100) for i in range(8) if user_vector[i] > 0]

        for name, percent in sorted(user_style_summary, key=lambda item: item[1], reverse=True):
            print(f"   - {name}: {percent:.2f}%")

        # [4] í˜ë¥´ì†Œë‚˜ ì¼ì¹˜ìœ¨ (â˜…ìˆ˜ì •ëœ ë¶€ë¶„â˜…)
        print("\n" + "=" * 50)
        print("âœ… [4] í˜ë¥´ì†Œë‚˜ ì¼ì¹˜ìœ¨ (ë‹¹ì‹ ì˜ ë¡¤ëª¨ë¸)")
        print("-" * 50)
        match_results = calculate_persona_match(user_vector)
        sorted_results = sorted(match_results.items(), key=lambda item: item[1], reverse=True)

        # í˜ë¥´ì†Œë‚˜ ì² í•™ ë°ì´í„° ë¡œë“œ
        philosophies = pd_data.PERSONA_PHILOSOPHY

        for i, (name, percent) in enumerate(sorted_results):
            # 15% ì´ìƒ ë¹„ì¤‘ì´ ìˆëŠ” ìœ ì˜ë¯¸í•œ í˜ë¥´ì†Œë‚˜ë§Œ ì¶œë ¥
            if percent > 15:
                if i == 0:
                    print(f"   ğŸ¥‡ {name}: {percent:.2f}% (ê°€ì¥ ìœ ì‚¬!)")
                else:
                    print(f"   ğŸ¥ˆ {name}: {percent:.2f}%")

                # 'ì™œ' ë§¤ì¹­ë˜ì—ˆëŠ”ì§€ ê·¼ê±°(ì² í•™)ë¥¼ ì¶œë ¥
                if name in philosophies:
                    print(f"       â¡ï¸ ì´ìœ : {philosophies[name]}\n")

        print("\n" + "=" * 50)